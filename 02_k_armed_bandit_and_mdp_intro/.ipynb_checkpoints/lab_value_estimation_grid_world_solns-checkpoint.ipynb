{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2ba6549-8b15-4f95-9615-549dd5fa2f7c",
   "metadata": {},
   "source": [
    "### Lab: Value Iteration in a Grid World [SOLUTIONS]\n",
    "\n",
    "Last updated: August 10, 2023\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afeab41-bd5f-40e8-ad2f-e8999f13ed45",
   "metadata": {},
   "source": [
    "#### Instructions:\n",
    "\n",
    "Implement value iteration for a $4 \\times 3$ gridworld environment. The actions are up, down, left and right. The actions are deterministic, meaning that the action selected will be taken with probability 1. There is a terminal state with reward +1 in the bottom right corner. All other rewards are 0. The discount factor is 0.9. Use tolerance $\\theta=0.01$.\n",
    "\n",
    "Your function should return an array with the estimated values for each state. For each sweep over the states, print out the intermediate array.\n",
    "\n",
    "**NOTE**: It is encouraged (but optional) create a GridWorld class that includes `value_iteration()` as a method. Then you would call that method to calculate and return the value function array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4deb2d6-a0ea-46bb-b0a9-e3fc15482e49",
   "metadata": {},
   "source": [
    "#### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09f89e37-d060-48ec-b1a6-809eba649178",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8d545c-bd94-4929-b3e5-e442b49c2934",
   "metadata": {},
   "source": [
    "**Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef874051-0cf7-4c70-b13e-1103e00e0f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'up':0,\n",
    "         'right':1,\n",
    "         'down':2,\n",
    "         'left':3,\n",
    "         'reward':1,\n",
    "         'gamma':0.9,\n",
    "         'theta':0.2,\n",
    "         'logging':False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf40646-b1e6-4a96-9841-6d0685975890",
   "metadata": {},
   "source": [
    "**Supporting class and functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "946b7215-bccf-4fdb-80f7-eeded53d68f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld():\n",
    "    def __init__(self, nrows, ncols, params):\n",
    "        self.nrows = nrows\n",
    "        self.ncols = ncols\n",
    "        self.up = params['up']\n",
    "        self.right = params['right']\n",
    "        self.down = params['down']\n",
    "        self.left = params['left']\n",
    "        self.reward = params['reward']\n",
    "        self.gamma = params['gamma']\n",
    "        self.theta = params['theta']\n",
    "        self.logging = params['logging']\n",
    "\n",
    "        # Initialize value function; here we arbitrarily use zero matrix. At terminal state, value is zero.\n",
    "        self.V = np.zeros((self.nrows, self.ncols))         \n",
    "\n",
    "    def prune_invalid_action(self, row, col):\n",
    "\n",
    "        actions = [self.up, self.right, self.down, self.left]\n",
    "\n",
    "        # if first row\n",
    "        if row == 0: \n",
    "            actions.remove(self.up) \n",
    "\n",
    "        # if last row\n",
    "        if row == self.nrows-1: \n",
    "            actions.remove(self.down) \n",
    "\n",
    "        # if leftmost column\n",
    "        if col == 0: \n",
    "            actions.remove(self.left) \n",
    "\n",
    "        # if rightmost column\n",
    "        if col == self.ncols-1: \n",
    "            actions.remove(self.right)\n",
    "\n",
    "        return actions\n",
    "\n",
    "\n",
    "    def get_reward(self, row, col):\n",
    "        # reward of 1 at bottom right, else 0\n",
    "\n",
    "        if (row == self.nrows-1) and (col == self.ncols-1):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def get_next_state(self, row, col, action):\n",
    "\n",
    "        # move up\n",
    "        if action == 0:\n",
    "            row -= 1\n",
    "\n",
    "        # move right\n",
    "        if action == 1:\n",
    "            col += 1\n",
    "\n",
    "        # move down\n",
    "        if action == 2:\n",
    "            row += 1\n",
    "\n",
    "        # move left\n",
    "        if action == 3:\n",
    "            col -= 1\n",
    "\n",
    "        return row, col     \n",
    "    \n",
    "    def value_iteration(self):\n",
    "\n",
    "        if self.logging:\n",
    "            print('V:\\n', self.V)\n",
    "            print('')\n",
    "\n",
    "        delta = 1\n",
    "        while delta > self.theta: \n",
    "            delta = 0\n",
    "\n",
    "            # Loop through all states \n",
    "            for row in range(self.nrows):\n",
    "                for col in range(self.ncols): \n",
    "\n",
    "                    # starting value in state V(s)\n",
    "                    v = self.V[row, col] \n",
    "\n",
    "                    # If not terminal state \n",
    "                    if row != self.nrows-1 or col != self.ncols-1: \n",
    "\n",
    "                        # given state, remove invalid actions \n",
    "                        actions = grid.prune_invalid_action(row, col)\n",
    "\n",
    "                        # Bellman equation for V'(s). Select V'(s) based on action yielding highest value.\n",
    "                        vmax = 0\n",
    "                        for action in actions:\n",
    "                            next_row, next_col = grid.get_next_state(row, col, action)\n",
    "                            reward = grid.get_reward(next_row, next_col)\n",
    "\n",
    "                            if self.logging:\n",
    "                                print('current state:', (row, col))\n",
    "                                print('valid actions:', actions)\n",
    "                                print('next state:', (next_row, next_col))\n",
    "                                print('reward:', reward)\n",
    "                                print('V[next_row, next_col]', grid.V[next_row, next_col])\n",
    "\n",
    "                            vmax = max(vmax, reward + grid.gamma * grid.V[next_row, next_col])\n",
    " \n",
    "                        grid.V[row, col] = vmax\n",
    "\n",
    "                        # check largest change in value function\n",
    "                        delta = max(delta, np.abs(vmax - v))  \n",
    "                        if self.logging:\n",
    "                            print('vmax:', vmax)\n",
    "                            print('delta:', delta)\n",
    "\n",
    "            print('V:\\n',grid.V)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5059685c-bb49-4907-88de-0ef495d02ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate the gridworld\n",
    "grid = GridWorld(4,3,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "285cc017-87cd-4b0d-9e0f-d41dc468b80d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V:\n",
      " [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n",
      "V:\n",
      " [[0.  0.  0. ]\n",
      " [0.  0.  0.9]\n",
      " [0.  0.9 1. ]\n",
      " [0.9 1.  0. ]]\n",
      "V:\n",
      " [[0.   0.   0.81]\n",
      " [0.   0.81 0.9 ]\n",
      " [0.81 0.9  1.  ]\n",
      " [0.9  1.   0.  ]]\n",
      "V:\n",
      " [[0.    0.729 0.81 ]\n",
      " [0.729 0.81  0.9  ]\n",
      " [0.81  0.9   1.   ]\n",
      " [0.9   1.    0.   ]]\n",
      "V:\n",
      " [[0.6561 0.729  0.81  ]\n",
      " [0.729  0.81   0.9   ]\n",
      " [0.81   0.9    1.    ]\n",
      " [0.9    1.     0.    ]]\n",
      "V:\n",
      " [[0.6561 0.729  0.81  ]\n",
      " [0.729  0.81   0.9   ]\n",
      " [0.81   0.9    1.    ]\n",
      " [0.9    1.     0.    ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6561, 0.729 , 0.81  ],\n",
       "       [0.729 , 0.81  , 0.9   ],\n",
       "       [0.81  , 0.9   , 1.    ],\n",
       "       [0.9   , 1.    , 0.    ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run value iteration\n",
    "grid.value_iteration()\n",
    "\n",
    "grid.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da323e8b-83f8-44c3-a449-845ea9e7b87c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
